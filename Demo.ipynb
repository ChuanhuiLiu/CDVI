{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo for CD-CVAE\n",
    "\n",
    "This is the demo Jupyter Notebook is helpful to repeat experiments in Censor-dependent Variational Inference. It includes\n",
    "\n",
    "- Script for training and tuning a state-of-the-art survival model.\n",
    "\n",
    "- Script for training and tuning CD-CVAE model and the variants.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Load and process dataset via Customized Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages to import\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pandas as pd\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# logistics on two-subfolder location\n",
    "project_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../'))\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "from auton_survival.datasets import load_dataset #https://github.com/autonlab/auton-survival\n",
    "\n",
    "from utils.override_functions import plot_performance_metrics\n",
    "from utils.preprocess import pre_process\n",
    "from utils.data_load import data_loader\n",
    "from pycox.evaluation import EvalSurv #https://github.com/havakv/pycox/blob/master/pycox/evaluation/eval_surv.py\n",
    "from auton_survival.estimators import SurvivalModel\n",
    "from utils.override_functions import survival_regression_metric_modified\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "name = 'SUPPORT'\n",
    "validation_metric = \"ctdpycox\"\n",
    "test_metric = \"ctd\"\n",
    "\n",
    "outcomes, features = data_loader(name)\n",
    "print(\"_______Preprocessing\"+str(name)+\" dataset started____________\")\n",
    "x_tr,y_tr,x_val,y_val,x_te,y_te= pre_process(features, outcomes,dataset=name,to_numpy=False,log=False)\n",
    "print(\"_______Preprocessing\"+str(name)+\"  finished____________\")\n",
    "\n",
    "# Define the times for model evaluation\n",
    "times = np.quantile(y_tr['time'][y_tr['event']==1], np.linspace(0.1, 1, 10)).tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training and tuning Deep Survival Machine (DSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"dsm\"\n",
    "\n",
    "# Define hyperparameters grid for tuning the model\n",
    "param_grid = {'k' : [3,  6],\n",
    "              'distribution' : ['LogNormal', 'Weibull'],\n",
    "              'learning_rate' : [ 1e-4, 1e-3],\n",
    "              'layers' : [ [100], [100, 100] ]\n",
    "             }\n",
    "params = ParameterGrid(param_grid)\n",
    "\n",
    "models = []\n",
    "for param in params:\n",
    "    model = SurvivalModel(modelname, random_seed=20, hyperparams=param)\n",
    "    \n",
    "    # The fit method is called to train the model\n",
    "    model.fit(x_tr, y_tr)\n",
    "\n",
    "    # Obtain survival probabilities for validation set and compute the Integrated Brier Score \n",
    "    predictions_val = model.predict_survival(x_val, times)\n",
    "\n",
    "    # Determine the evaluation metric\n",
    "    metric_val = survival_regression_metric_modified(validation_metric, y_val, predictions_val, times, y_tr)\n",
    "    models.append([metric_val, model])\n",
    "    \n",
    "# Select the best model based on the mean metric value computed for the validation set\n",
    "metric_vals = [i[0] for i in models]\n",
    "first_min_idx = metric_vals.index(min(metric_vals))\n",
    "model = models[first_min_idx][1]\n",
    "\n",
    "# Obtain survival probabilities for test set\n",
    "times = np.quantile(y_te['time'][y_te['event']==1], [0.75,0.75,0.75]).tolist()\n",
    "predictions_te = model.predict_survival(x_te, times)\n",
    "metric = survival_regression_metric_modified(test_metric,y_te,predictions_te,times,y_tr) #len(times)\n",
    "print(metric)\n",
    "print(\"_______Evaluating the performance on test dataset using \"+str(test_metric)+ \", the average value is \"+str(round(np.mean(metric),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Training and tuning Censor-dependent Variational Autoencoders (CD-CVAEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available models\n",
    "from model.cd_cvae import CDCVAE\n",
    "from model.cd_diwae import CDDIWAE\n",
    "from model.cd_iwae import CDIWAE\n",
    "from model.cvae import CVAE\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "rng = np.random.default_rng(seed=1)\n",
    "\n",
    "model = CDCVAE(encoder_layer_sizes=[x_tr.shape[-1]+1,x_tr.shape[-1]*12,x_tr.shape[-1]*24,x_tr.shape[-1]*6,x_tr.shape[-1]*2], \n",
    "               latent_dim=int(x_tr.shape[-1]/2), px=x_tr.shape[-1],\n",
    "               decoder_layer_sizes=[x_tr.shape[-1]*4,x_tr.shape[-1]*8,x_tr.shape[-1]*2,int(x_tr.shape[-1]/2),1],\n",
    "               sigma_learning=\"joint\",primative =\"gumbel\",dropout=0.95)\n",
    "\n",
    "# Pre-train CDCVAE with cross validation\n",
    "model.fit(train_data=[x_tr,y_tr,x_val,y_val],batch_size = 200,num_epochs=5000,learning_rate=0.001,criterion=validation_metric,patience = 1000,temperature=0.9)\n",
    "\n",
    "# Evaluate CDCVAE on test dataset\n",
    "times = np.quantile(y_te['time'][y_te['event']==1], 0.75).tolist() # or times = np.unique(y_te['time'][y_te['event']==1]).tolist() \n",
    "predictions = model.predict(x_te,times,format=\"pre\",expo=True)\n",
    "print(predictions)\n",
    "metric = survival_regression_metric_modified(test_metric,y_te,predictions,times,y_tr) #len(times)\n",
    "print(\"_______Evaluating the performance on test dataset using ,\"+str(test_metric)+\", the average value is \"+str(round(np.mean(metric),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use simulations dataset alone, the example below is helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import iwae_loss_fn, KL_divergence\n",
    "kwargs={\"clevel\":\"all_censor\"}\n",
    "outcomes, features,latent_dict = data_loader(\"SIMULATE\",**kwargs)\n",
    "\n",
    "n = len(features['x'])\n",
    "x_train = torch.tensor(features[\"x\"].to_numpy(), dtype=torch.float32).reshape(n,1)\n",
    "y_train = torch.tensor(outcomes[\"time\"].to_numpy(), dtype=torch.float32).reshape(n,1)\n",
    "e_train = torch.tensor(outcomes[\"event\"].to_numpy(), dtype=torch.float32)\n",
    "\n",
    "true_mu = torch.tensor(latent_dict[\"mu\"], dtype=torch.float32)\n",
    "true_log_var = torch.zeros_like(true_mu, dtype=torch.float32,device=true_mu.device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
